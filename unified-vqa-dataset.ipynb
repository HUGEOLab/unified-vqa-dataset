{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59bebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 配置加载完成\n",
      "GitHub Base URL: https://github.com/HUGEOLab/unified-vqa-dataset/tree/main\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# 配置GitHub信息\n",
    "class Config:\n",
    "    # 本地数据路径\n",
    "    BASE_LOCAL_PATH = \"/mnt/mydev2/M256374\"\n",
    "    \n",
    "    # 数据集路径\n",
    "    AOKVQA_PATH = f\"{BASE_LOCAL_PATH}/A_OK_VQA\"\n",
    "    OKVQA_PATH = f\"{BASE_LOCAL_PATH}/OK_VQA\"\n",
    "    FVQA_PATH = f\"{BASE_LOCAL_PATH}/F_VQA\"\n",
    "    \n",
    "    # ⚠️ GitHub配置 - 请修改为你的账户信息\n",
    "    GITHUB_USERNAME = \"HUGEOLab\"  # 修改为你的GitHub用户名\n",
    "    GITHUB_REPO = \"unified-vqa-dataset\"\n",
    "    GITHUB_BRANCH = \"main\"\n",
    "    BASE_URL = f\"https://github.com/{GITHUB_USERNAME}/{GITHUB_REPO}/tree/{GITHUB_BRANCH}\"\n",
    "    \n",
    "    # 输出路径\n",
    "    OUTPUT_JSON = \"unified_dataset.json\"\n",
    "    OUTPUT_STATS = \"dataset_stats.json\"\n",
    "    \n",
    "    # 本地GitHub仓库路径（如果已克隆）\n",
    "    LOCAL_GITHUB_REPO = \"/mnt/mydev2/M256374/unified-vqa-dataset\"  # 例如: \"/path/to/unified-vqa-dataset\"\n",
    "\n",
    "print(\"✓ 配置加载完成\")\n",
    "print(f\"GitHub Base URL: {Config.BASE_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1745d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 工具函数定义完成\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_json(path: str) -> Any:\n",
    "    \"\"\"加载JSON文件\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"文件未找到: {path}\")\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Any, path: str) -> None:\n",
    "    \"\"\"保存JSON文件\"\"\"\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✓ 已保存: {path}\")\n",
    "\n",
    "def copy_image_to_github_repo(src_path: str, relative_dest_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    复制图片到本地GitHub仓库\n",
    "    \n",
    "    Args:\n",
    "        src_path: 源图片路径\n",
    "        relative_dest_path: 相对于GitHub仓库的目标路径\n",
    "    \n",
    "    Returns:\n",
    "        bool: 是否成功复制\n",
    "    \"\"\"\n",
    "    if Config.LOCAL_GITHUB_REPO is None:\n",
    "        return False\n",
    "    \n",
    "    dest_path = os.path.join(Config.LOCAL_GITHUB_REPO, relative_dest_path)\n",
    "    dest_dir = os.path.dirname(dest_path)\n",
    "    \n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(src_path):\n",
    "        if not os.path.exists(dest_path):\n",
    "            shutil.copy2(src_path, dest_path)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(\"✓ 工具函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aff8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "处理 A-OKVQA 数据集\n",
      "============================================================\n",
      "\n",
      "加载 train 集合...\n",
      "处理 17056 个样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17056/17056 [02:45<00:00, 102.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "加载 val 集合...\n",
      "处理 1145 个样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1145/1145 [00:12<00:00, 94.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ A-OKVQA 处理完成: 18201 个样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class AOKVQAProcessor:\n",
    "    @staticmethod\n",
    "    def process() -> List[Dict]:\n",
    "        \"\"\"处理A-OKVQA数据集\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"处理 A-OKVQA 数据集\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        unified_samples = []\n",
    "        \n",
    "        for split in ['train', 'val']:\n",
    "            json_path = f\"{Config.AOKVQA_PATH}/json_files/{split}_datasets.json\"\n",
    "            \n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"⚠ 未找到: {json_path}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n加载 {split} 集合...\")\n",
    "            data = load_json(json_path)\n",
    "            \n",
    "            if not isinstance(data, list):\n",
    "                data = [data]\n",
    "            \n",
    "            print(f\"处理 {len(data)} 个样本...\")\n",
    "            for sample in tqdm(data):\n",
    "                # 提取原始image_path\n",
    "                original_image_path = sample.get('image_path', '')\n",
    "                filename = os.path.basename(original_image_path)\n",
    "                image_year = \"train2017\" if split == \"train\" else \"val2017\"\n",
    "                \n",
    "                local_relative_path = f\"aokvqa/{image_year}/{filename}\"\n",
    "                image_url = f\"{Config.BASE_URL}/data/{local_relative_path}\"\n",
    "                \n",
    "                # 如果有本地GitHub仓库，复制图片\n",
    "                if Config.LOCAL_GITHUB_REPO:\n",
    "                    src_image_path = os.path.join(Config.AOKVQA_PATH, image_year, filename)\n",
    "                    copy_image_to_github_repo(src_image_path, local_relative_path)\n",
    "                \n",
    "                # 创建统一格式的样本\n",
    "                unified_sample = {\n",
    "                    \"dataset\": \"aokvqa\",\n",
    "                    \"split\": sample.get('split', split),\n",
    "                    \"image_id\": sample.get('image_id'),\n",
    "                    \"question_id\": sample.get('question_id'),\n",
    "                    \"question\": sample.get('question'),\n",
    "                    \"image_url_path\": image_url,\n",
    "                    \"image_local_path\": local_relative_path,\n",
    "                    # 保留原始字段\n",
    "                    \"choices\": sample.get('choices'),\n",
    "                    \"correct_choice_idx\": sample.get('correct_choice_idx'),\n",
    "                    \"direct_answers\": sample.get('direct_answers'),\n",
    "                    \"difficult_direct_answer\": sample.get('difficult_direct_answer'),\n",
    "                    \"rationales\": sample.get('rationales')\n",
    "                }\n",
    "                \n",
    "                unified_samples.append(unified_sample)\n",
    "        \n",
    "        print(f\"\\n✓ A-OKVQA 处理完成: {len(unified_samples)} 个样本\")\n",
    "        return unified_samples\n",
    "\n",
    "# 执行处理\n",
    "aokvqa_samples = AOKVQAProcessor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24da450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "处理 OK-VQA 数据集\n",
      "============================================================\n",
      "\n",
      "加载 train 集合...\n",
      "处理 9009 个样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9009/9009 [02:52<00:00, 52.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "加载 val 集合...\n",
      "处理 5046 个样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5046/5046 [00:58<00:00, 86.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ OK-VQA 处理完成: 14055 个样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class OKVQAProcessor:\n",
    "    @staticmethod\n",
    "    def process() -> List[Dict]:\n",
    "        \"\"\"处理OK-VQA数据集\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"处理 OK-VQA 数据集\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        unified_samples = []\n",
    "        \n",
    "        # 修正路径\n",
    "        base_path = \"/mnt/mydev2/M256374/previous_work/for_research/selection\"\n",
    "        data_files = {\n",
    "            'train': f\"{base_path}/train_data.json\",\n",
    "            'val': f\"{base_path}/val_data.json\"\n",
    "        }\n",
    "        \n",
    "        for split, json_path in data_files.items():\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"⚠ 未找到: {json_path}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n加载 {split} 集合...\")\n",
    "            data = load_json(json_path)\n",
    "            \n",
    "            if not isinstance(data, list):\n",
    "                data = [data]\n",
    "            \n",
    "            print(f\"处理 {len(data)} 个样本...\")\n",
    "            for sample in tqdm(data):\n",
    "                # 提取原始image_path并获取文件名\n",
    "                original_image_path = sample.get('image_path', '')\n",
    "                filename = os.path.basename(original_image_path)\n",
    "                image_year = \"train2014\" if split == \"train\" else \"val2014\"\n",
    "                \n",
    "                local_relative_path = f\"okvqa/{image_year}/{filename}\"\n",
    "                image_url = f\"{Config.BASE_URL}/data/{local_relative_path}\"\n",
    "                \n",
    "                # 如果有本地GitHub仓库，复制图片\n",
    "                if Config.LOCAL_GITHUB_REPO:\n",
    "                    src_image_path = os.path.join(Config.OKVQA_PATH, image_year, filename)\n",
    "                    copy_image_to_github_repo(src_image_path, local_relative_path)\n",
    "                \n",
    "                # 创建统一格式的样本\n",
    "                unified_sample = {\n",
    "                    \"dataset\": \"okvqa\",\n",
    "                    \"split\": split,\n",
    "                    \"question_id\": sample.get('question_id'),\n",
    "                    \"question\": sample.get('question'),\n",
    "                    \"image_url_path\": image_url,\n",
    "                    \"image_local_path\": local_relative_path,\n",
    "                    # 保留原始字段\n",
    "                    \"answers\": sample.get('answers')\n",
    "                }\n",
    "                \n",
    "                unified_samples.append(unified_sample)\n",
    "        \n",
    "        print(f\"\\n✓ OK-VQA 处理完成: {len(unified_samples)} 个样本\")\n",
    "        return unified_samples\n",
    "\n",
    "# 执行处理\n",
    "okvqa_samples = OKVQAProcessor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef1662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "处理 F-VQA 数据集\n",
      "============================================================\n",
      "加载数据...\n",
      "处理 5826 个样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5826/5826 [00:13<00:00, 423.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ F-VQA 处理完成: 5826 个样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FVQAProcessor:\n",
    "    @staticmethod\n",
    "    def process() -> List[Dict]:\n",
    "        \"\"\"处理F-VQA数据集\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"处理 F-VQA 数据集\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        unified_samples = []\n",
    "        \n",
    "        json_path = f\"{Config.FVQA_PATH}/input_files/all_data.json\"\n",
    "        \n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"⚠ 未找到: {json_path}\")\n",
    "            return unified_samples\n",
    "        \n",
    "        print(f\"加载数据...\")\n",
    "        data = load_json(json_path)\n",
    "        \n",
    "        # F-VQA的数据结构是字典，键是question_id\n",
    "        items = data.items() if isinstance(data, dict) else enumerate(data)\n",
    "        items_list = list(items)\n",
    "        \n",
    "        print(f\"处理 {len(items_list)} 个样本...\")\n",
    "        for question_id, sample in tqdm(items_list):\n",
    "            if isinstance(sample, dict):\n",
    "                # 提取image_path\n",
    "                original_image_path = sample.get('image_path', '')\n",
    "                filename = os.path.basename(original_image_path)\n",
    "                \n",
    "                local_relative_path = f\"fvqa/images/{filename}\"\n",
    "                image_url = f\"{Config.BASE_URL}/data/{local_relative_path}\"\n",
    "                \n",
    "                # 如果有本地GitHub仓库，复制图片\n",
    "                if Config.LOCAL_GITHUB_REPO:\n",
    "                    src_image_path = os.path.join(Config.FVQA_PATH, 'new_dataset_release', 'images', filename)\n",
    "                    copy_image_to_github_repo(src_image_path, local_relative_path)\n",
    "                \n",
    "                # 创建统一格式的样本\n",
    "                unified_sample = {\n",
    "                    \"dataset\": \"fvqa\",\n",
    "                    \"split\": \"FULL\",\n",
    "                    \"question_id\": str(question_id),\n",
    "                    \"question\": sample.get('question'),\n",
    "                    \"answer\": sample.get('answer'),\n",
    "                    \"image_url_path\": image_url,\n",
    "                    \"image_local_path\": local_relative_path,\n",
    "                    # 保留其他原始字段\n",
    "                    \"fact_surface\": sample.get('fact_surface'),\n",
    "                    \"ans_source\": sample.get('ans_source'),\n",
    "                    \"visual_concept\": sample.get('visual_concept'),\n",
    "                    \"kb_source\": sample.get('kb_source'),\n",
    "                    \"fact\": sample.get('fact'),\n",
    "                    \"img_file\": sample.get('img_file')\n",
    "                }\n",
    "                \n",
    "                unified_samples.append(unified_sample)\n",
    "        \n",
    "        print(f\"\\n✓ F-VQA 处理完成: {len(unified_samples)} 个样本\")\n",
    "        return unified_samples\n",
    "\n",
    "# 执行处理\n",
    "fvqa_samples = FVQAProcessor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db028800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "数据集合并完成\n",
      "============================================================\n",
      "A-OKVQA: 18201 个样本\n",
      "OK-VQA: 14055 个样本\n",
      "F-VQA: 5826 个样本\n",
      "总计: 38082 个样本\n",
      "\n",
      "============================================================\n",
      "数据验证\n",
      "============================================================\n",
      "✓ 所有必要字段完整\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 合并所有样本\n",
    "all_samples = aokvqa_samples + okvqa_samples + fvqa_samples\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"数据集合并完成\")\n",
    "print(\"=\"*60)\n",
    "print(f\"A-OKVQA: {len(aokvqa_samples)} 个样本\")\n",
    "print(f\"OK-VQA: {len(okvqa_samples)} 个样本\")\n",
    "print(f\"F-VQA: {len(fvqa_samples)} 个样本\")\n",
    "print(f\"总计: {len(all_samples)} 个样本\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 7: 数据验证\n",
    "# ============================================================================\n",
    "\n",
    "def validate_dataset(samples: List[Dict]) -> None:\n",
    "    \"\"\"验证数据集完整性\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"数据验证\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    required_fields = ['dataset', 'split', 'question', 'image_url_path']\n",
    "    \n",
    "    missing_count = 0\n",
    "    for i, sample in enumerate(samples):\n",
    "        for field in required_fields:\n",
    "            if field not in sample or sample[field] is None:\n",
    "                print(f\"✗ 样本 {i}: 缺少字段 '{field}'\")\n",
    "                missing_count += 1\n",
    "    \n",
    "    if missing_count == 0:\n",
    "        print(\"✓ 所有必要字段完整\")\n",
    "    else:\n",
    "        print(f\"⚠ 发现 {missing_count} 个缺失字段\")\n",
    "\n",
    "validate_dataset(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd1408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "显示 AOKVQA 数据集的样本\n",
      "============================================================\n",
      "\n",
      "样本 1:\n",
      "  数据集: AOKVQA\n",
      "  分割: train\n",
      "  问题: What is the man by the bags awaiting?...\n",
      "  选项: ['skateboarder', 'train', 'delivery', 'cab']\n",
      "  图片URL: https://github.com/HUGEOLab/unified-vqa-dataset/tree/main/data/aokvqa/train2017/000000299207.jpg\n",
      "\n",
      "============================================================\n",
      "显示 OKVQA 数据集的样本\n",
      "============================================================\n",
      "\n",
      "样本 1:\n",
      "  数据集: OKVQA\n",
      "  分割: train\n",
      "  问题: What is the hairstyle of the blond called?...\n",
      "  答案: ['pony tail', 'pony tail', 'pony tail']...\n",
      "  图片URL: https://github.com/HUGEOLab/unified-vqa-dataset/tree/main/data/okvqa/train2014/COCO_train2014_000000051606.jpg\n",
      "\n",
      "============================================================\n",
      "显示 FVQA 数据集的样本\n",
      "============================================================\n",
      "\n",
      "样本 1:\n",
      "  数据集: FVQA\n",
      "  分割: FULL\n",
      "  问题: Which object can be found in a jazz club...\n",
      "  答案: trumpet\n",
      "  图片URL: https://github.com/HUGEOLab/unified-vqa-dataset/tree/main/data/fvqa/images/ILSVRC2012_test_00050748.JPEG\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 8: 显示样本示例\n",
    "# ============================================================================\n",
    "\n",
    "def show_samples(samples: List[Dict], dataset: str = None, num: int = 2) -> None:\n",
    "    \"\"\"显示样本\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if dataset:\n",
    "        print(f\"显示 {dataset.upper()} 数据集的样本\")\n",
    "        display_samples = [s for s in samples if s['dataset'] == dataset]\n",
    "    else:\n",
    "        print(\"显示随机样本\")\n",
    "        display_samples = samples\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, sample in enumerate(display_samples[:num]):\n",
    "        print(f\"\\n样本 {i+1}:\")\n",
    "        print(f\"  数据集: {sample['dataset'].upper()}\")\n",
    "        print(f\"  分割: {sample.get('split', 'N/A')}\")\n",
    "        print(f\"  问题: {sample['question'][:80]}...\")\n",
    "        if 'choices' in sample and sample['choices']:\n",
    "            print(f\"  选项: {sample['choices']}\")\n",
    "        if 'answers' in sample and sample['answers']:\n",
    "            print(f\"  答案: {sample['answers'][:3]}...\")\n",
    "        if 'answer' in sample:\n",
    "            print(f\"  答案: {sample['answer']}\")\n",
    "        print(f\"  图片URL: {sample['image_url_path']}\")\n",
    "\n",
    "# 显示各数据集的样本\n",
    "for dataset in ['aokvqa', 'okvqa', 'fvqa']:\n",
    "    show_samples(all_samples, dataset=dataset, num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e67508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "数据统计信息\n",
      "============================================================\n",
      "\n",
      "总样本数: 38082\n",
      "\n",
      "按数据集统计:\n",
      "  AOKVQA: 18201 个样本\n",
      "  OKVQA: 14055 个样本\n",
      "  FVQA: 5826 个样本\n",
      "\n",
      "按分割统计:\n",
      "  train: 26065 个样本\n",
      "  val: 6191 个样本\n",
      "\n",
      "数据量:\n",
      "  JSON大小: 22.85 MB\n",
      "✓ 已保存: unified_dataset.json\n",
      "✓ 已保存: dataset_stats.json\n",
      "\n",
      "✓ 数据已保存完成\n",
      "\n",
      "✓ 验证: 成功加载 38082 个样本\n",
      "✓ 第一个样本的数据集: aokvqa\n",
      "✓ 最后一个样本的数据集: fvqa\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 9: 生成统计信息\n",
    "# ============================================================================\n",
    "\n",
    "def generate_statistics(samples: List[Dict]) -> Dict:\n",
    "    \"\"\"生成数据统计\"\"\"\n",
    "    stats = {\n",
    "        \"total_samples\": len(samples),\n",
    "        \"by_dataset\": {},\n",
    "        \"by_split\": {},\n",
    "        \"sample_size\": {}\n",
    "    }\n",
    "    \n",
    "    # 按数据集统计\n",
    "    for dataset in ['aokvqa', 'okvqa', 'fvqa']:\n",
    "        count = len([s for s in samples if s['dataset'] == dataset])\n",
    "        stats['by_dataset'][dataset] = count\n",
    "    \n",
    "    # 按分割统计\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        count = len([s for s in samples if s.get('split') == split])\n",
    "        if count > 0:\n",
    "            stats['by_split'][split] = count\n",
    "    \n",
    "    # 计算JSON大小\n",
    "    json_str = json.dumps(samples)\n",
    "    stats['sample_size']['json_bytes'] = len(json_str.encode('utf-8'))\n",
    "    stats['sample_size']['json_mb'] = len(json_str.encode('utf-8')) / (1024 * 1024)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 生成统计\n",
    "stats = generate_statistics(all_samples)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"数据统计信息\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n总样本数: {stats['total_samples']}\")\n",
    "print(f\"\\n按数据集统计:\")\n",
    "for dataset, count in stats['by_dataset'].items():\n",
    "    print(f\"  {dataset.upper()}: {count} 个样本\")\n",
    "\n",
    "print(f\"\\n按分割统计:\")\n",
    "for split, count in stats['by_split'].items():\n",
    "    print(f\"  {split}: {count} 个样本\")\n",
    "\n",
    "print(f\"\\n数据量:\")\n",
    "print(f\"  JSON大小: {stats['sample_size']['json_mb']:.2f} MB\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 10: 保存统一数据集和统计信息\n",
    "# ============================================================================\n",
    "\n",
    "# 保存统一数据集\n",
    "save_json(all_samples, Config.OUTPUT_JSON)\n",
    "\n",
    "# 保存统计信息\n",
    "save_json(stats, Config.OUTPUT_STATS)\n",
    "\n",
    "print(\"\\n✓ 数据已保存完成\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 11: 加载和验证保存的数据\n",
    "# ============================================================================\n",
    "\n",
    "# 加载验证\n",
    "with open(Config.OUTPUT_JSON, 'r') as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "print(f\"\\n✓ 验证: 成功加载 {len(loaded_data)} 个样本\")\n",
    "print(f\"✓ 第一个样本的数据集: {loaded_data[0]['dataset']}\")\n",
    "print(f\"✓ 最后一个样本的数据集: {loaded_data[-1]['dataset']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee40344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GitHub上传指南\n",
      "============================================================\n",
      "\n",
      "✓ 本地图片已复制到: /mnt/mydev2/M256374/unified-vqa-dataset\n",
      "\n",
      "请执行以下命令上传到GitHub:\n",
      "\n",
      "1. 进入仓库目录:\n",
      "   cd /mnt/mydev2/M256374/unified-vqa-dataset\n",
      "\n",
      "2. 查看状态:\n",
      "   git status\n",
      "\n",
      "3. 添加所有文件:\n",
      "   git add .\n",
      "\n",
      "4. 提交更改:\n",
      "   git commit -m \"Add unified VQA dataset with 38082 samples\"\n",
      "\n",
      "5. 上传到GitHub:\n",
      "   git push origin main\n",
      "\n",
      "6. 验证上传:\n",
      "   访问: https://github.com/HUGEOLab/unified-vqa-dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 12: GitHub上传指南\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GitHub上传指南\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Config.LOCAL_GITHUB_REPO:\n",
    "    print(f\"\"\"\n",
    "✓ 本地图片已复制到: {Config.LOCAL_GITHUB_REPO}\n",
    "\n",
    "请执行以下命令上传到GitHub:\n",
    "\n",
    "1. 进入仓库目录:\n",
    "   cd {Config.LOCAL_GITHUB_REPO}\n",
    "\n",
    "2. 查看状态:\n",
    "   git status\n",
    "\n",
    "3. 添加所有文件:\n",
    "   git add .\n",
    "\n",
    "4. 提交更改:\n",
    "   git commit -m \"Add unified VQA dataset with {len(all_samples)} samples\"\n",
    "\n",
    "5. 上传到GitHub:\n",
    "   git push origin main\n",
    "\n",
    "6. 验证上传:\n",
    "   访问: https://github.com/{Config.GITHUB_USERNAME}/{Config.GITHUB_REPO}\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"\"\"\n",
    "⚠ 未设置本地GitHub仓库路径\n",
    "\n",
    "如果要自动复制图片到GitHub仓库，请:\n",
    "1. 创建GitHub仓库: {Config.GITHUB_REPO}\n",
    "2. 克隆到本地: git clone https://github.com/{Config.GITHUB_USERNAME}/{Config.GITHUB_REPO}.git\n",
    "3. 修改Config.LOCAL_GITHUB_REPO = \"/path/to/{Config.GITHUB_REPO}\"\n",
    "4. 重新运行脚本\n",
    "\n",
    "或者手动执行:\n",
    "1. 上传 unified_dataset.json 到仓库\n",
    "2. 上传 dataset_stats.json 到仓库\n",
    "3. 创建对应的目录结构并上传图片\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3542306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ fixed 38082 samples, skipped 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "INPUT = \"/mnt/mydev2/M256374/unified-vqa-dataset/unified_dataset.json\"\n",
    "OUTPUT = \"/mnt/mydev2/M256374/unified-vqa-dataset/unified_dataset.json\"\n",
    "\n",
    "HF_BASE = \"https://huggingface.co/datasets/Geojx/unified-vqa-images/resolve/main\"\n",
    "\n",
    "def to_rel_path(s: str) -> str:\n",
    "    \"\"\"Turn various forms into a clean relative path like aokvqa/train2017/xxx.jpg\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "\n",
    "    # Case 1: already relative path\n",
    "    if \"://\" not in s:\n",
    "        return s.lstrip(\"/\")\n",
    "\n",
    "    # Case 2: github URL like .../data/aokvqa/train2017/xxx.jpg\n",
    "    # Extract the part after \"/data/\" if present.\n",
    "    marker = \"/data/\"\n",
    "    if marker in s:\n",
    "        return s.split(marker, 1)[1].lstrip(\"/\")\n",
    "\n",
    "    # Otherwise: unknown URL, return empty to avoid making garbage HF urls\n",
    "    return \"\"\n",
    "\n",
    "with open(INPUT, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fixed = 0\n",
    "skipped = 0\n",
    "\n",
    "for item in data:\n",
    "    # 1) best source: image_local_path\n",
    "    rel = to_rel_path(item.get(\"image_local_path\", \"\"))\n",
    "\n",
    "    # 2) fallback: some datasets might store local path in other keys\n",
    "    if not rel:\n",
    "        rel = to_rel_path(item.get(\"image_path\", \"\"))\n",
    "\n",
    "    # 3) last resort: try image_url_path (github url)\n",
    "    if not rel:\n",
    "        rel = to_rel_path(item.get(\"image_url_path\", \"\"))\n",
    "\n",
    "    if not rel:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # optional: fix typo extension\n",
    "    if rel.endswith(\".jpp\"):\n",
    "        rel = rel[:-4] + \".jpg\"\n",
    "\n",
    "    item[\"image_local_path\"] = rel              # normalize it\n",
    "    item[\"image_url\"] = f\"{HF_BASE}/{rel}\"      # hf url\n",
    "\n",
    "    fixed += 1\n",
    "\n",
    "with open(OUTPUT, \"w\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✓ fixed {fixed} samples, skipped {skipped}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
